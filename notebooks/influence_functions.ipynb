{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cce776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data import (\n",
    "    WavFeature,\n",
    "    MeanScoreFeature,\n",
    "    FilenameFeature,\n",
    "    process_fn_mean,\n",
    ")\n",
    "from models.wav2vec_net import MosPredictor\n",
    "from slates import EvalSlate\n",
    "from swag.posteriors import SWAG\n",
    "from tabula.dataloader import DataLoader, Dataset\n",
    "from tabula.helpers import CheckpointHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52928780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import nn\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random\n",
    "\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.experimental import optimizers\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import IPython\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = \"ood\"\n",
    "\n",
    "if TRACK == \"ood\":\n",
    "    conf_file = \"../ood_config.yaml\"\n",
    "    with open(conf_file, \"r\") as f:\n",
    "        conf = OmegaConf.load(f)\n",
    "    conf.checkpoint.path = \"../checkpoints/finetune-ood-0.001-1234/bestmodel.pt\"\n",
    "else:\n",
    "    conf_file = \"../ssl_config.yaml\"\n",
    "    with open(conf_file, \"r\") as f:\n",
    "        conf = OmegaConf.load(f)\n",
    "    conf.checkpoint.path = \"../checkpoints/wav2vec-swag-0.001/bestmodel.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36361c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f150ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(conf.seed)\n",
    "torch.cuda.manual_seed(conf.seed)\n",
    "\n",
    "model = MosPredictor(**conf.model)\n",
    "swag_model = SWAG(\n",
    "    MosPredictor,\n",
    "    no_cov_mat=False,\n",
    "    max_num_models=10,\n",
    "    **conf.model,\n",
    ")\n",
    "swag_model.cuda()\n",
    "swag_model.eval()\n",
    "\n",
    "checkpoint_helper = CheckpointHelper(\n",
    "    conf.exp_name,\n",
    "    {\n",
    "        \"model\": model,\n",
    "        \"swag_model\": swag_model,\n",
    "    },\n",
    "    save_epoch=conf.checkpoint.epoch,\n",
    "    save_iters=conf.checkpoint.iters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = checkpoint_helper.load(conf.checkpoint.path)\n",
    "\n",
    "swag_model.sample(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b249545",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_features = {\n",
    "    'wav': WavFeature(length_modulo=320),\n",
    "    'mean_score': MeanScoreFeature(),\n",
    "    'fname': FilenameFeature(),\n",
    "}\n",
    "\n",
    "train_set = Dataset(\n",
    "    conf.data.train_path,\n",
    "    data_features,\n",
    "    proc_fn=partial(process_fn_mean, ood_path=conf.data.valid_path_ood, inf_filter=False),\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set, num_workers=8, shuffle=False, batch_size=conf.eval.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a3ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "def predict(params, activations):\n",
    "  # per-example predictions\n",
    "    w, b = params\n",
    "    outputs = jnp.dot(w, activations) + b\n",
    "    activations = nn.sigmoid(outputs) * 4 + 1\n",
    "  \n",
    "    return activations\n",
    "\n",
    "batched_predict = vmap(predict, in_axes=(None, 0))\n",
    "\n",
    "def l1loss(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    return jnp.mean(jnp.abs(preds - targets))\n",
    "\n",
    "def l2loss(params, images, targets):\n",
    "    preds = batched_predict(params, images)\n",
    "    return jnp.mean((preds - targets) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all layers for a fully-connected neural network with sizes \"sizes\"\n",
    "def init_network_params(sizes, key):\n",
    "    keys = random.split(key, len(sizes))\n",
    "    return [random_layer_params(m, n, k) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]\n",
    "\n",
    "layer_sizes = [768, 1]\n",
    "step_size = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc2550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment depending on whether you want to port the SWAG model or vanilla model\n",
    "\n",
    "params = [\n",
    "    jnp.array(swag_model.base.output_layer.weight.data.cpu().numpy()),\n",
    "    jnp.array(swag_model.base.output_layer.bias.data.cpu().numpy()),\n",
    "]\n",
    "\n",
    "# params = [\n",
    "#     jnp.array(model.output_layer.weight.data.cpu().numpy()),\n",
    "#     jnp.array(model.output_layer.bias.data.cpu().numpy()),\n",
    "# ]\n",
    "print(params[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "train_data = []\n",
    "train_loss = []\n",
    "for i, batch_data in enumerate(train_loader):\n",
    "    with torch.no_grad():\n",
    "        feats = swag_model.base.ssl_model(batch_data['wav']['data'].cuda(), mask=False, features_only=True)\n",
    "        feats = torch.mean(feats['x'], 1)\n",
    "        feats = feats.data.cpu().numpy()\n",
    "    loss = l2loss(params, feats, batch_data['mean_score'].data.cpu().numpy())\n",
    "    train_data.append({\n",
    "        'mean_score': batch_data['mean_score'].data.cpu().numpy(),\n",
    "        'feats': feats,\n",
    "        'fname': batch_data['fname'],\n",
    "    })\n",
    "    train_loss.append(loss)\n",
    "epoch_time = time.time() - start_time\n",
    "\n",
    "print(\"Epoch {} in {:0.2f} sec\".format(1, epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffefdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.lib import xla_bridge\n",
    "print(xla_bridge.get_backend().platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38acef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_idx = jnp.argsort(jnp.array(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca0968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "from jax import jvp\n",
    "from jax.tree_util import tree_flatten, tree_leaves\n",
    "\n",
    "\n",
    "def hvp(params, x, t, v):\n",
    "    loss_fn = lambda params: l2loss(params, x, t)\n",
    "    return jvp(grad(loss_fn), (params,), (v,))[1]\n",
    "\n",
    "\n",
    "def single_loss(params, sentence, targets):\n",
    "    preds = predict(params, sentence)\n",
    "    return jnp.mean(jnp.abs(preds - targets))\n",
    "\n",
    "\n",
    "@jit\n",
    "def lissa_estimate(params, x, t, v, h_estimate, damp=0.01, scale=25):\n",
    "    # Recursively caclulate h_estimate\n",
    "    hv = hvp(params, x, t, h_estimate)\n",
    "    h_estimate = jax.tree_multimap(lambda x, y, z: x + (1 - damp) * y - z / scale, v, h_estimate, hv)\n",
    "    return h_estimate\n",
    "\n",
    "\n",
    "def get_s_test(z_test, t_test, params, z_loader, damp=0.01, scale=25.0,\n",
    "               recursion_depth=5000):\n",
    "    v = grad(single_loss)(params, z_test, t_test)\n",
    "    h_estimate = v.copy()\n",
    "    for depth in range(recursion_depth):\n",
    "        x, t, _ = next(iter(z_loader))\n",
    "        h_estimate = lissa_estimate(params, x, t, v, h_estimate,\n",
    "                                    damp=damp, scale=scale)\n",
    "\n",
    "        if depth % 500 == 0:\n",
    "            print(\"Calc. s_test recursions: \", depth, recursion_depth)\n",
    "\n",
    "    return h_estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e778990",
   "metadata": {},
   "source": [
    "# Select point with largest error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3badd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ranked_idx[-1]\n",
    "target_label = train_data[idx]['mean_score']\n",
    "test_input = train_data[idx]['feats']\n",
    "print(\"Testing id:\", idx)\n",
    "\n",
    "preds = predict(params, test_input[0])\n",
    "print(train_data[idx]['fname'])\n",
    "print(f\"Real label: {target_label[0]}\")\n",
    "print(f\"Original prediction: {preds[0]}\")\n",
    "IPython.display.Audio(f\"/home/jiameng/data_voicemos/phase1-{TRACK}/DATA/wav/{train_data[idx]['fname'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2615603",
   "metadata": {},
   "source": [
    "# Estimate s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca8db0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    return data[0]['feats'], data[0]['mean_score'], data[0]['fname']\n",
    "\n",
    "z_loader = torch.utils.data.DataLoader(train_data, collate_fn=collate_fn)\n",
    "\n",
    "s_test = get_s_test(test_input[0], target_label, params, z_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cca5349",
   "metadata": {},
   "source": [
    "# Calculate influence functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbaf543",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def get_influence(x, t, params, s_test):\n",
    "    grad_z_vec = grad(single_loss)(params, x, t)\n",
    "    tmp_influence = jax.tree_multimap(lambda x, y: x * y, grad_z_vec, s_test)\n",
    "    tmp_influence = -np.sum(jnp.array([jnp.sum(i) for i in tree_leaves(tmp_influence)])) / len(train_data)\n",
    "    return tmp_influence\n",
    "\n",
    "influences = []\n",
    "for i, (x, t, f) in enumerate(z_loader):\n",
    "    z = [i for i in zip(x, t)]\n",
    "    tmp_influence = vmap(partial(get_influence, params=params, s_test=s_test), in_axes=(0, 0))(x, t)\n",
    "    influences.extend(tmp_influence)\n",
    "    if i % 50 == 0:\n",
    "        print(i)\n",
    "\n",
    "helpful = np.argsort(influences)\n",
    "not_helpful = helpful[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in not_helpful[:10]:\n",
    "    print(train_data[i]['fname'][0], influences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebfd03",
   "metadata": {},
   "source": [
    "# Look at most unhelpful points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da850442",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0\n",
    "f_idx = not_helpful[N]\n",
    "\n",
    "fname = train_data[f_idx]['fname'][0]\n",
    "df = pd.read_csv(f'/home/jiameng/data_voicemos/phase1-{TRACK}/DATA/sets/train_mos_list.txt', names=['fname', 'score'])\n",
    "filtered_df = df[df.fname == fname]\n",
    "print(filtered_df)\n",
    "\n",
    "IPython.display.Audio(f\"/home/jiameng/data_voicemos/phase1-{TRACK}/DATA/wav/{fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb3e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
